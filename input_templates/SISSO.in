!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
! Below are the list of keywords for all the features in SISSO. Use exclamation mark,!,to comment out a line
! Explanations for the keywords: (R) for regression, (C) for classification, (R&C) for both.
! The setting below serve only as a sample, please change to proper values for your application. 
!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
ptype=1                 !Property type 1: regression, 2:classification.
ntask=1                 !(R&C) Multi-task learning (MTL) is invoked if >1.
task_weighting=1        !(R) MTL 1: no weighting (tasks treated equally), 2: weighted by the # of samples.
scmt=.false.            !(R) Sign-Constrained MTL is invoked if .true.
desc_dim=2              !(R&C) Dimension of the descriptor, a hyperparmaeter.
nsample=5               !(R) Number of samples in train.dat. For MTL, set nsample=N1,N2,... for many tasks
!nsample=(n1,n2,...)    !(C) Number of samples. For MTL, separate the set nsample=(n1,n2,...),(m1,m2,...),...
restart=0               !(R&C) 0: starts from scratch, 1: continues the job(see progress in the file CONTINUE)

!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
! Feature construction (FC) and sure independence screening (SIS)
! Implemented operators:(+)(-)(*)(/)(exp)(exp-)(^-1)(^2)(^3)(sqrt)(cbrt)(log)(|-|)(scd)(^6)(sin)(cos)
! scd: standard Cauchy distribution
! Make sure to set proper 'subs_sis' according to the 'desc_dim'. E.g.: (subs_sis=100000,desc_dim=2) has
! similar comput. demand with (2000,3) because both need (L0) to evaluate C(subs_sis,desc_dim) ~ 10^10 models.
!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
nsf= 3                 !(R&C) Number of scalar features provided in the file train.dat
opset='(+)(-)(*)(/)'   !(R&C) Please customize your operators from the list shown above.
fcomplexity=3          !(R&C) Feature complexity (# of operators in the feature), integer from 0 to usually 7.
dimclass=(1:2)(3:3)    !(R&C) (n1:n2): features from n1 to n2 arranged in train.dat have same dimension/unit
maxfval_lb=1e-3        !(R&C) Treated as zero-feature if the max. abs. value of the feature < maxfval_lb.
maxfval_ub=1e5         !(R&C) Treated as infinity-feature if the max. abs. value of the feature > maxfval_ub)
subs_sis=20            !(R&C) Size of the SIS-selected subspace from the created (huge) feature space. 

!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
! Descriptor identification (DI) via sparse regression
!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
method='L0'            !(R&C) 'L0' or 'L1L0'(LASSO+L0). The 'L0' is recommended for both ptype=1 and 2.
L1L0_size4L0= 1        !(R) For LASSO+L0, number of LASSO-selected features for the L0.
fit_intercept=.true.   !(R) Fit to a nonzero (.true.) or zero (.false.) intercept for the linear model.
metric='RMSE'          !(R) The metric for model selection in regression: RMSE or MaxAE (max absolute error)
nm_output=100          !(R&C) Number of the top models to output (see the folder 'models')
isconvex=(1,1)         !(C) Each data group constrained to be convex domain, 1: YES; 0: NO
width=0.001            !(C) Boundary tolerance for classification 
